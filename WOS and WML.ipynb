{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/pmservice/ai-openscale-tutorials/raw/master/notebooks/images/banner.png\" align=\"left\" alt=\"banner\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Watson Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook should be run in a Watson Studio project, using **Default Python 3.6** runtime environment. It requires service credentials for the following Cloud services:\n",
    "  * Watson OpenScale\n",
    "  * Watson Machine Learning\n",
    "  \n",
    "If you have a paid Cloud account, you may also provision a **Databases for PostgreSQL** or **Db2 Warehouse** service to take full advantage of integration with Watson Studio and continuous learning services. If you choose not to provision this paid service, you can use the free internal PostgreSQL storage with OpenScale, but will not be able to configure continuous learning for your model.\n",
    "\n",
    "The notebook will train, create and deploy a German Credit Risk model, configure OpenScale to monitor that deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents\n",
    "\n",
    "- [Setup](#setup)\n",
    "- [Model building and deployment](#model)\n",
    "- [OpenScale configuration](#openscale)\n",
    "- [Fairness monitoring and explanations](#fairness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup <a name=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Package installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied, skipping upgrade: six in /opt/conda/envs/Python36/lib/python3.6/site-packages (from h5py->ibm-ai-openscale) (1.12.0)\n",
      "Requirement already satisfied: toolz>=0.7.3; extra == \"array\" in /opt/conda/envs/Python36/lib/python3.6/site-packages (from dask[array]>=0.9.0->scikit-image>=0.12->lime) (0.9.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade ibm-ai-openscale --no-cache | tail -n 1\n",
    "!pip install lime --no-cache | tail -n 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provision services and configure credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have not already, provision an instance of IBM Watson OpenScale using the [OpenScale link in the Cloud catalog](https://cloud.ibm.com/catalog/services/watson-openscale)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your Cloud API key can be generated by going to the [**Users** section of the Cloud console](https://cloud.ibm.com/iam#/users). From that page, click your name, scroll down to the **API Keys** section, and click **Create an IBM Cloud API key**. Give your key a name and click **Create**, then copy the created key and paste it below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** You can also get OpenScale `API_KEY` using IBM CLOUD CLI.\n",
    "\n",
    "How to install IBM Cloud (bluemix) console: [instruction](https://console.bluemix.net/docs/cli/reference/ibmcloud/download_cli.html#install_use)\n",
    "\n",
    "How to get api key using console:\n",
    "```\n",
    "bx login --sso\n",
    "bx iam api-key-create 'my_key'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CLOUD_API_KEY = \"32-Xiv7GKYY_KhPRYoYYZCk6P46G5nLyjBzzWdRZ4c_m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code was removed by Watson Studio for sharing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next you will need credentials for Watson Machine Learning. If you already have a WML instance, you may use credentials for it. To provision a new Lite instance of WML, use the [Cloud catalog](https://cloud.ibm.com/catalog/services/machine-learning), give your service a name, and click **Create**. Once your instance is created, click the **Service Credentials** link on the left side of the screen. Click the **New credential** button, give your credentials a name, and click **Add**. Your new credentials can be accessed by clicking the **View credentials** button. Copy and paste your WML credentials into the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "WML_CREDENTIALS = {\n",
    "  'apikey': '-p_Z7pY3v7JWzQksmi2Z3WOHie_IlJLZyqd6IudJKkbg',\n",
    "  'iam_apikey_description': 'Auto generated apikey during resource-key operation for Instance - crn:v1:bluemix:public:pm-20:us-south:a/d2c5c1830d2a6fc88d77c610c09bb1ed:fe0b229f-5167-4b9d-8b72-87bb3dcf4542::',\n",
    "  'iam_apikey_name': 'auto-generated-apikey-0b1319e1-e295-4d64-93c7-86a84c2d11ab',\n",
    "  'iam_role_crn': 'crn:v1:bluemix:public:iam::::serviceRole:Writer',\n",
    "  'iam_serviceid_crn': 'crn:v1:bluemix:public:iam-identity::a/d2c5c1830d2a6fc88d77c610c09bb1ed::serviceid:ServiceId-663e92d9-d7f4-4903-b5fc-e2ad5878abed',\n",
    "  'instance_id': 'fe0b229f-5167-4b9d-8b72-87bb3dcf4542',\n",
    "  'password': '19a7b0c7-f3fe-4155-ab11-c9c061e46fc5',\n",
    "  'url': 'https://us-south.ml.cloud.ibm.com',\n",
    "  'username': '0b1319e1-e295-4d64-93c7-86a84c2d11ab'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code was removed by Watson Studio for sharing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial can use Databases for PostgreSQL, Db2 Warehouse, or a free internal verison of PostgreSQL to create a datamart for OpenScale.\n",
    "\n",
    "If you have previously configured OpenScale, it will use your existing datamart, and not interfere with any models you are currently monitoring. Do not update the cell below.\n",
    "\n",
    "If you do not have a paid Cloud account or would prefer not to provision this paid service, you may use the free internal PostgreSQL service with OpenScale. Do not update the cell below.\n",
    "\n",
    "To provision a new instance of Db2 Warehouse, locate [Db2 Warehouse in the Cloud catalog](https://cloud.ibm.com/catalog/services/db2-warehouse), give your service a name, and click **Create**. Once your instance is created, click the **Service Credentials** link on the left side of the screen. Click the **New credential** button, give your credentials a name, and click **Add**. Your new credentials can be accessed by clicking the **View credentials** button. Copy and paste your Db2 Warehouse credentials into the cell below.\n",
    "\n",
    "To provision a new instance of Databases for PostgreSQL, locate [Databases for PostgreSQL in the Cloud catalog](https://cloud.ibm.com/catalog/services/databases-for-postgresql), give your service a name, and click **Create**. Once your instance is created, click the **Service Credentials** link on the left side of the screen. Click the **New credential** button, give your credentials a name, and click **Add**. Your new credentials can be accessed by clicking the **View credentials** button. Copy and paste your Databases for PostgreSQL credentials into the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DB_CREDENTIALS = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__If you previously configured OpenScale to use the free internal version of PostgreSQL, you can switch to a new datamart using a paid database service.__ If you would like to delete the internal PostgreSQL configuration and create a new one using service credentials supplied in the cell above, set the __KEEP_MY_INTERNAL_POSTGRES__ variable below to __False__ below. In this case, the notebook will remove your existing internal PostgreSQL datamart and create a new one with the supplied credentials. __*NO DATA MIGRATION WILL OCCUR.*__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEEP_MY_INTERNAL_POSTGRES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the notebook\n",
    "\n",
    "At this point, the notebook is ready to run. You can either run the cells one at a time, or click the **Kernel** option above and select **Restart and Run All** to run all the cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building and deployment <a name=\"model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you will learn how to train Scikit-learn model and next deploy it as web-service using Watson Machine Learning service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data from github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-11-12 03:25:01--  https://raw.githubusercontent.com/pmservice/ai-openscale-tutorials/master/assets/historical_data/german_credit_risk/wml/german_credit_data_biased_training.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 199.232.8.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|199.232.8.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 689622 (673K) [text/plain]\n",
      "Saving to: ‘german_credit_data_biased_training.csv’\n",
      "\n",
      "100%[======================================>] 689,622     --.-K/s   in 0.03s   \n",
      "\n",
      "2019-11-12 03:25:02 (21.6 MB/s) - ‘german_credit_data_biased_training.csv’ saved [689622/689622]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!rm german_credit_data_biased_training.csv\n",
    "!wget https://raw.githubusercontent.com/pmservice/ai-openscale-tutorials/master/assets/historical_data/german_credit_risk/wml/german_credit_data_biased_training.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data_df = pd.read_csv('german_credit_data_biased_training.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CheckingStatus</th>\n",
       "      <th>LoanDuration</th>\n",
       "      <th>CreditHistory</th>\n",
       "      <th>LoanPurpose</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>ExistingSavings</th>\n",
       "      <th>EmploymentDuration</th>\n",
       "      <th>InstallmentPercent</th>\n",
       "      <th>Sex</th>\n",
       "      <th>OthersOnLoan</th>\n",
       "      <th>...</th>\n",
       "      <th>OwnsProperty</th>\n",
       "      <th>Age</th>\n",
       "      <th>InstallmentPlans</th>\n",
       "      <th>Housing</th>\n",
       "      <th>ExistingCreditsCount</th>\n",
       "      <th>Job</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Telephone</th>\n",
       "      <th>ForeignWorker</th>\n",
       "      <th>Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_to_200</td>\n",
       "      <td>31</td>\n",
       "      <td>credits_paid_to_date</td>\n",
       "      <td>other</td>\n",
       "      <td>1889</td>\n",
       "      <td>100_to_500</td>\n",
       "      <td>less_1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>savings_insurance</td>\n",
       "      <td>32</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>No Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>less_0</td>\n",
       "      <td>18</td>\n",
       "      <td>credits_paid_to_date</td>\n",
       "      <td>car_new</td>\n",
       "      <td>462</td>\n",
       "      <td>less_100</td>\n",
       "      <td>1_to_4</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>savings_insurance</td>\n",
       "      <td>37</td>\n",
       "      <td>stores</td>\n",
       "      <td>own</td>\n",
       "      <td>2</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>No Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>less_0</td>\n",
       "      <td>15</td>\n",
       "      <td>prior_payments_delayed</td>\n",
       "      <td>furniture</td>\n",
       "      <td>250</td>\n",
       "      <td>less_100</td>\n",
       "      <td>1_to_4</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>real_estate</td>\n",
       "      <td>28</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>2</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>No Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_to_200</td>\n",
       "      <td>28</td>\n",
       "      <td>credits_paid_to_date</td>\n",
       "      <td>retraining</td>\n",
       "      <td>3693</td>\n",
       "      <td>less_100</td>\n",
       "      <td>greater_7</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>savings_insurance</td>\n",
       "      <td>32</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>No Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no_checking</td>\n",
       "      <td>28</td>\n",
       "      <td>prior_payments_delayed</td>\n",
       "      <td>education</td>\n",
       "      <td>6235</td>\n",
       "      <td>500_to_1000</td>\n",
       "      <td>greater_7</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>57</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>2</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>Risk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  CheckingStatus  LoanDuration           CreditHistory LoanPurpose  \\\n",
       "0       0_to_200            31    credits_paid_to_date       other   \n",
       "1         less_0            18    credits_paid_to_date     car_new   \n",
       "2         less_0            15  prior_payments_delayed   furniture   \n",
       "3       0_to_200            28    credits_paid_to_date  retraining   \n",
       "4    no_checking            28  prior_payments_delayed   education   \n",
       "\n",
       "   LoanAmount ExistingSavings EmploymentDuration  InstallmentPercent     Sex  \\\n",
       "0        1889      100_to_500             less_1                   3  female   \n",
       "1         462        less_100             1_to_4                   2  female   \n",
       "2         250        less_100             1_to_4                   2    male   \n",
       "3        3693        less_100          greater_7                   3    male   \n",
       "4        6235     500_to_1000          greater_7                   3    male   \n",
       "\n",
       "  OthersOnLoan  ...       OwnsProperty Age  InstallmentPlans Housing  \\\n",
       "0         none  ...  savings_insurance  32              none     own   \n",
       "1         none  ...  savings_insurance  37            stores     own   \n",
       "2         none  ...        real_estate  28              none     own   \n",
       "3         none  ...  savings_insurance  32              none     own   \n",
       "4         none  ...            unknown  57              none     own   \n",
       "\n",
       "  ExistingCreditsCount      Job Dependents  Telephone ForeignWorker     Risk  \n",
       "0                    1  skilled          1       none           yes  No Risk  \n",
       "1                    2  skilled          1       none           yes  No Risk  \n",
       "2                    2  skilled          1        yes            no  No Risk  \n",
       "3                    1  skilled          1       none           yes  No Risk  \n",
       "4                    2  skilled          1       none           yes     Risk  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns:  ['CheckingStatus', 'LoanDuration', 'CreditHistory', 'LoanPurpose', 'LoanAmount', 'ExistingSavings', 'EmploymentDuration', 'InstallmentPercent', 'Sex', 'OthersOnLoan', 'CurrentResidenceDuration', 'OwnsProperty', 'Age', 'InstallmentPlans', 'Housing', 'ExistingCreditsCount', 'Job', 'Dependents', 'Telephone', 'ForeignWorker', 'Risk']\n",
      "Number of columns:  21\n"
     ]
    }
   ],
   "source": [
    "print('Columns: ', list(data_df.columns))\n",
    "print('Number of columns: ', len(data_df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the data contains twenty one fields. `Risk` field is the one you would like to predict using feedback data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records:  5000\n"
     ]
    }
   ],
   "source": [
    "print('Number of records: ', data_df.Risk.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Risk\n",
       "No Risk    3330\n",
       "Risk       1670\n",
       "Name: Risk, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_count = data_df.groupby('Risk')['Risk'].count()\n",
    "target_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a model\n",
    "In this section you will learn how to:\n",
    "\n",
    "- Prepare data for training a model\n",
    "- Create machine learning pipeline\n",
    "- Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"Scikit German Risk Model\"\n",
    "DEPLOYMENT_NAME = \"Scikit German Risk Deployment\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You will start with importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data_df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_idx = np.s_[0:-1]\n",
    "all_records_idx = np.s_[:]\n",
    "first_record_idx = np.s_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step you will encode target column labels into numeric values. You can use `inverse_transform` to decode numeric predictions into labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_fields = [type(fld) is str for fld in train_data.iloc[first_record_idx, features_idx]]\n",
    "ct = ColumnTransformer([(\"ohe\", OneHotEncoder(), list(np.array(train_data.columns)[features_idx][string_fields]))])\n",
    "clf_linear = SGDClassifier(loss='log', penalty='l2', max_iter=1000, tol=1e-5)\n",
    "\n",
    "pipeline_linear = Pipeline([('ct', ct), ('clf_linear', clf_linear)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_model = pipeline_linear.fit(train_data.drop('Risk', axis=1), train_data.Risk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7433364915354226\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "predictions = risk_model.predict(test_data.drop('Risk', axis=1))\n",
    "indexed_preds = [0 if prediction=='No Risk' else 1 for prediction in predictions]\n",
    "\n",
    "real_observations = test_data.Risk.replace('Risk', 1)\n",
    "real_observations = real_observations.replace('No Risk', 0).values\n",
    "\n",
    "auc = roc_auc_score(real_observations, indexed_preds)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, the notebook uses the supplied Watson Machine Learning credentials to save the model (including the pipeline) to the WML instance. Previous versions of the model are removed so that the notebook can be run again, resetting all data for another demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient\n",
    "import json\n",
    "\n",
    "wml_client = WatsonMachineLearningAPIClient(WML_CREDENTIALS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove existing model and deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting deployment id 210b79ce-bc62-46fa-970f-2a2937b775db\n",
      "Deleting model id cfc72978-bc21-43a7-865e-6516aa67c1b4\n",
      "------------------------------------  -------------------------------------------  ------------------------  ---------\n",
      "GUID                                  NAME                                         CREATED                   FRAMEWORK\n",
      "ffca250f-e69f-45e6-85aa-52de989588a3  Credit Risk w OP                             2019-10-24T11:45:18.088Z  mllib-2.3\n",
      "1911f946-4f5b-4275-861d-0e242630b43d  Credit Risk w/o OP                           2019-10-24T10:33:11.587Z  mllib-2.3\n",
      "e2242b38-4152-4169-b053-ad2afb453676  BUM                                          2019-05-16T13:11:56.111Z  wml-1.1\n",
      "55c4eb54-4605-4e39-b794-96f4cd19abbe  Customer_Churn_Model                         2019-05-01T06:23:25.772Z  wml-1.1\n",
      "0165864a-0d37-4d9a-a4bc-1805b696dcdd  credit-risk                                  2019-03-15T06:08:18.522Z  mllib-2.3\n",
      "eb8d8746-16ed-4d3c-bf87-d29d88afa158  Sentiment Prediction                         2018-07-31T14:56:43.914Z  mllib-2.1\n",
      "7cbe9d2b-73fb-44da-8ee0-9634520891bd  Fraud Classification Unbiased - Spark Model  2018-07-31T04:13:25.266Z  mllib-2.1\n",
      "338301ab-78d4-4387-bdd7-68e826159020  Fraud Classification Biased - Spark Model    2018-07-31T04:13:25.242Z  mllib-2.1\n",
      "------------------------------------  -------------------------------------------  ------------------------  ---------\n"
     ]
    }
   ],
   "source": [
    "model_deployment_ids = wml_client.deployments.get_uids()\n",
    "for deployment_id in model_deployment_ids:\n",
    "    deployment = wml_client.deployments.get_details(deployment_id)\n",
    "    model_id = deployment['entity']['deployable_asset']['guid']\n",
    "    if deployment['entity']['name'] == DEPLOYMENT_NAME:\n",
    "        print('Deleting deployment id', deployment_id)\n",
    "        wml_client.deployments.delete(deployment_id)\n",
    "        print('Deleting model id', model_id)\n",
    "        wml_client.repository.delete(model_id)\n",
    "wml_client.repository.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_props = {\n",
    "    wml_client.repository.ModelMetaNames.NAME: \"{}\".format(MODEL_NAME),\n",
    "    wml_client.repository.ModelMetaNames.EVALUATION_METHOD: \"binary\",\n",
    "    wml_client.repository.ModelMetaNames.EVALUATION_METRICS: [\n",
    "        {\n",
    "           \"name\": \"areaUnderROC\",\n",
    "           \"value\": auc,\n",
    "           \"threshold\": 0.7\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing model ...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "wml_models = wml_client.repository.get_details()\n",
    "model_uid = None\n",
    "for model_in in wml_models['models']['resources']:\n",
    "    if MODEL_NAME == model_in['entity']['name']:\n",
    "        model_uid = model_in['metadata']['guid']\n",
    "        break\n",
    "\n",
    "if model_uid is None:\n",
    "    print(\"Storing model ...\")\n",
    "\n",
    "    published_model_details = wml_client.repository.store_model(model=risk_model, meta_props=model_props, training_data=data_df.drop(['Risk'], axis=1), training_target=data_df.Risk)\n",
    "    model_uid = wml_client.repository.get_model_uid(published_model_details)\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2ba77eb1-26b3-48ed-b33a-98baccee3bc6'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_uid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next section of the notebook deploys the model as a RESTful web service in Watson Machine Learning. The deployed model will have a scoring URL you can use to send data to the model for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying model...\n",
      "\n",
      "\n",
      "#######################################################################################\n",
      "\n",
      "Synchronous deployment creation for uid: '2ba77eb1-26b3-48ed-b33a-98baccee3bc6' started\n",
      "\n",
      "#######################################################################################\n",
      "\n",
      "\n",
      "INITIALIZING\n",
      "DEPLOY_SUCCESS\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------------------\n",
      "Successfully finished deployment creation, deployment_uid='24a0e195-2546-483f-86bc-1c15b25482cb'\n",
      "------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Model id: 2ba77eb1-26b3-48ed-b33a-98baccee3bc6\n",
      "Deployment id: 24a0e195-2546-483f-86bc-1c15b25482cb\n"
     ]
    }
   ],
   "source": [
    "wml_deployments = wml_client.deployments.get_details()\n",
    "deployment_uid = None\n",
    "for deployment in wml_deployments['resources']:\n",
    "    if DEPLOYMENT_NAME == deployment['entity']['name']:\n",
    "        deployment_uid = deployment['metadata']['guid']\n",
    "        break\n",
    "\n",
    "if deployment_uid is None:\n",
    "    print(\"Deploying model...\")\n",
    "\n",
    "    deployment = wml_client.deployments.create(artifact_uid=model_uid, name=DEPLOYMENT_NAME, asynchronous=False)\n",
    "    deployment_uid = wml_client.deployments.get_uid(deployment)\n",
    "    \n",
    "print(\"Model id: {}\".format(model_uid))\n",
    "print(\"Deployment id: {}\".format(deployment_uid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [\"CheckingStatus\", \"LoanDuration\", \"CreditHistory\", \"LoanPurpose\", \"LoanAmount\", \"ExistingSavings\",\n",
    "                  \"EmploymentDuration\", \"InstallmentPercent\", \"Sex\", \"OthersOnLoan\", \"CurrentResidenceDuration\",\n",
    "                  \"OwnsProperty\", \"Age\", \"InstallmentPlans\", \"Housing\", \"ExistingCreditsCount\", \"Job\", \"Dependents\",\n",
    "                  \"Telephone\", \"ForeignWorker\"]\n",
    "values = [\n",
    "            [\"no_checking\", 13, \"credits_paid_to_date\", \"car_new\", 1343, \"100_to_500\", \"1_to_4\", 2, \"female\", \"none\", 3,\n",
    "             \"savings_insurance\", 46, \"none\", \"own\", 2, \"skilled\", 1, \"none\", \"yes\"],\n",
    "            [\"no_checking\", 24, \"prior_payments_delayed\", \"furniture\", 4567, \"500_to_1000\", \"1_to_4\", 4, \"male\", \"none\",\n",
    "             4, \"savings_insurance\", 36, \"none\", \"free\", 2, \"management_self-employed\", 1, \"none\", \"yes\"],\n",
    "        ]\n",
    "\n",
    "scoring_payload = {\"fields\": fields, \"values\": values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fields': ['prediction', 'probability'],\n",
       " 'values': [['No Risk', [0.5355367798367918, 0.4644632201632082]],\n",
       "  ['No Risk', [0.6521880639637132, 0.3478119360362868]]]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring_url = wml_client.deployments.get_scoring_url(deployment)\n",
    "\n",
    "wml_client.deployments.score(scoring_url, scoring_payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure OpenScale <a name=\"openscale\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook will now import the necessary libraries and set up a Python OpenScale client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ibm_ai_openscale import APIClient\n",
    "from ibm_ai_openscale.engines import *\n",
    "from ibm_ai_openscale.utils import *\n",
    "from ibm_ai_openscale.supporting_classes import PayloadRecord, Feature\n",
    "from ibm_ai_openscale.supporting_classes.enums import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Watson OpenScale GUID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each instance of OpenScale has a unique ID. We can get this value using the Cloud API key specified at the beginning of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d711594f-93d6-49e0-8955-8c544344191b\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from ibm_ai_openscale.utils import get_instance_guid\n",
    "\n",
    "\n",
    "WOS_GUID = get_instance_guid(api_key=CLOUD_API_KEY)\n",
    "WOS_CREDENTIALS = {\n",
    "    \"instance_guid\": WOS_GUID,\n",
    "    \"apikey\": CLOUD_API_KEY,\n",
    "    \"url\": \"https://api.aiopenscale.cloud.ibm.com\"\n",
    "}\n",
    "\n",
    "if WOS_GUID is None:\n",
    "    print('Watson OpenScale GUID NOT FOUND')\n",
    "else:\n",
    "    print(WOS_GUID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.17'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_client = APIClient(aios_credentials=WOS_CREDENTIALS)\n",
    "ai_client.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create schema and datamart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up datamart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Watson OpenScale uses a database to store payload logs and calculated metrics. If database credentials were **not** supplied above, the notebook will use the free, internal lite database. If database credentials were supplied, the datamart will be created there **unless** there is an existing datamart **and** the **KEEP_MY_INTERNAL_POSTGRES** variable is set to **True**. If an OpenScale datamart exists in Db2 or PostgreSQL, the existing datamart will be used and no data will be overwritten.\n",
    "\n",
    "Prior instances of the German Credit model will be removed from OpenScale monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing internal datamart.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    data_mart_details = ai_client.data_mart.get_details()\n",
    "    if 'internal_database' in data_mart_details and data_mart_details['internal_database']:\n",
    "        if KEEP_MY_INTERNAL_POSTGRES:\n",
    "            print('Using existing internal datamart.')\n",
    "        else:\n",
    "            if DB_CREDENTIALS is None:\n",
    "                print('No postgres credentials supplied. Using existing internal datamart')\n",
    "            else:\n",
    "                print('Switching to external datamart')\n",
    "                ai_client.data_mart.delete(force=True)\n",
    "                ai_client.data_mart.setup(db_credentials=DB_CREDENTIALS)\n",
    "    else:\n",
    "        print('Using existing external datamart')\n",
    "except:\n",
    "    if DB_CREDENTIALS is None:\n",
    "        print('Setting up internal datamart')\n",
    "        ai_client.data_mart.setup(internal_db=True)\n",
    "    else:\n",
    "        print('Setting up external datamart')\n",
    "        try:\n",
    "            ai_client.data_mart.setup(db_credentials=DB_CREDENTIALS)\n",
    "        except:\n",
    "            print('Setup failed, trying Db2 setup')\n",
    "            ai_client.data_mart.setup(db_credentials=DB_CREDENTIALS, schema=DB_CREDENTIALS['username'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'database_configuration': {},\n",
       " 'internal_database': True,\n",
       " 'internal_database_pool': 'compose-psql',\n",
       " 'service_instance_crn': 'crn:v1:bluemix:public:aiopenscale:us-south:a/d2c5c1830d2a6fc88d77c610c09bb1ed:d711594f-93d6-49e0-8955-8c544344191b::',\n",
       " 'status': {'state': 'active'}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_mart_details = ai_client.data_mart.get_details()\n",
    "data_mart_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bind machine learning engines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Watson OpenScale needs to be bound to the Watson Machine Learning instance to capture payload data into and out of the model. If this binding already exists, this code will output a warning message and use the existing binding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** You can bind more than one engine instance if needed by calling `ai_client.data_mart.bindings.add` method. Next, you can refer to particular binding using `binding_uid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning during bind instance.\n",
      "Status code: 409, body: {\"errors\":[{\"code\":\"AIQCS0010W\",\"message\":\"Service Binding with this id is already defined\"}],\"trace\":\"ODUxNTg5NGYtMDA1NC00NWZlLTkwYTktZmE0YjUzZjMxNzIy\"}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<HTML>\n",
       "        <body>\n",
       "            <h3>Service bindings</h3>\n",
       "            <table style='border: 1px solid #dddddd; font-family: Courier'>\n",
       "                <th style='border: 1px solid #dddddd'>uid</th><th style='border: 1px solid #dddddd'>name</th><th style='border: 1px solid #dddddd'>service_type</th><th style='border: 1px solid #dddddd'>created</th>\n",
       "                <tr><td style='border: 1px solid #dddddd'>fe0b229f-5167-4b9d-8b72-87bb3dcf4542</td><td style='border: 1px solid #dddddd'>WML instance</td><td style='border: 1px solid #dddddd'>watson_machine_learning</td><td style='border: 1px solid #dddddd'>2019-11-12T03:00:55.362Z</td></tr>\n",
       "            </table>\n",
       "        </body>\n",
       "        </HTML>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "binding_uid = ai_client.data_mart.bindings.add('WML instance', WatsonMachineLearningInstance(WML_CREDENTIALS))\n",
    "if binding_uid is None:\n",
    "    binding_uid = ai_client.data_mart.bindings.get_details()['service_bindings'][0]['metadata']['guid']\n",
    "bindings_details = ai_client.data_mart.bindings.get_details()\n",
    "ai_client.data_mart.bindings.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fe0b229f-5167-4b9d-8b72-87bb3dcf4542\n"
     ]
    }
   ],
   "source": [
    "print(binding_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<HTML>\n",
       "        <body>\n",
       "            <h3>Available assets</h3>\n",
       "            <table style='border: 1px solid #dddddd; font-family: Courier'>\n",
       "                <th style='border: 1px solid #dddddd'>source_uid</th><th style='border: 1px solid #dddddd'>name</th><th style='border: 1px solid #dddddd'>created</th><th style='border: 1px solid #dddddd'>type</th><th style='border: 1px solid #dddddd'>frameworks</th><th style='border: 1px solid #dddddd'>binding_uid</th><th style='border: 1px solid #dddddd'>is_subscribed</th>\n",
       "                <tr><td style='border: 1px solid #dddddd'>2ba77eb1-26b3-48ed-b33a-98baccee3bc6</td><td style='border: 1px solid #dddddd'>Scikit German Risk Model</td><td style='border: 1px solid #dddddd'>2019-11-12T03:26:05.123Z</td><td style='border: 1px solid #dddddd'>model</td><td style='border: 1px solid #dddddd'>scikit-learn-0.20</td><td style='border: 1px solid #dddddd'>fe0b229f-5167-4b9d-8b72-87bb3dcf4542</td><td style='border: 1px solid #dddddd'>False</td></tr><tr><td style='border: 1px solid #dddddd'>ffca250f-e69f-45e6-85aa-52de989588a3</td><td style='border: 1px solid #dddddd'>Credit Risk w OP</td><td style='border: 1px solid #dddddd'>2019-10-24T11:45:35.871Z</td><td style='border: 1px solid #dddddd'>model</td><td style='border: 1px solid #dddddd'>mllib-2.3</td><td style='border: 1px solid #dddddd'>fe0b229f-5167-4b9d-8b72-87bb3dcf4542</td><td style='border: 1px solid #dddddd'>False</td></tr><tr><td style='border: 1px solid #dddddd'>1911f946-4f5b-4275-861d-0e242630b43d</td><td style='border: 1px solid #dddddd'>Credit Risk w/o OP</td><td style='border: 1px solid #dddddd'>2019-10-24T10:33:46.276Z</td><td style='border: 1px solid #dddddd'>model</td><td style='border: 1px solid #dddddd'>mllib-2.3</td><td style='border: 1px solid #dddddd'>fe0b229f-5167-4b9d-8b72-87bb3dcf4542</td><td style='border: 1px solid #dddddd'>False</td></tr>\n",
       "            </table>\n",
       "        </body>\n",
       "        </HTML>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ai_client.data_mart.bindings.list_assets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subscriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove existing credit risk subscriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code removes previous subscriptions to the German Credit model to refresh the monitors with the new model and new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted existing subscription for Scikit German Risk Model\n"
     ]
    }
   ],
   "source": [
    "subscriptions_uids = ai_client.data_mart.subscriptions.get_uids()\n",
    "for subscription in subscriptions_uids:\n",
    "    sub_name = ai_client.data_mart.subscriptions.get_details(subscription)['entity']['asset']['name']\n",
    "    if sub_name == MODEL_NAME:\n",
    "        ai_client.data_mart.subscriptions.delete(subscription)\n",
    "        print('Deleted existing subscription for', MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code creates the model subscription in OpenScale using the Python client API. Note that we need to provide the model unique identifier, and some information about the model itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "subscription = ai_client.data_mart.subscriptions.add(WatsonMachineLearningAsset(\n",
    "    model_uid,\n",
    "    problem_type=ProblemType.BINARY_CLASSIFICATION,\n",
    "    input_data_type=InputDataType.STRUCTURED,\n",
    "    label_column='Risk',\n",
    "    prediction_column='prediction',\n",
    "    probability_column='probability',\n",
    "    feature_columns = [\"CheckingStatus\",\"LoanDuration\",\"CreditHistory\",\"LoanPurpose\",\"LoanAmount\",\"ExistingSavings\",\"EmploymentDuration\",\"InstallmentPercent\",\"Sex\",\"OthersOnLoan\",\"CurrentResidenceDuration\",\"OwnsProperty\",\"Age\",\"InstallmentPlans\",\"Housing\",\"ExistingCreditsCount\",\"Job\",\"Dependents\",\"Telephone\",\"ForeignWorker\"],\n",
    "    categorical_columns = [\"CheckingStatus\",\"CreditHistory\",\"LoanPurpose\",\"ExistingSavings\",\"EmploymentDuration\",\"Sex\",\"OthersOnLoan\",\"OwnsProperty\",\"InstallmentPlans\",\"Housing\",\"Job\",\"Telephone\",\"ForeignWorker\"]\n",
    "))\n",
    "\n",
    "if subscription is None:\n",
    "    print('Subscription already exists; get the existing one')\n",
    "    subscriptions_uids = ai_client.data_mart.subscriptions.get_uids()\n",
    "    for sub in subscriptions_uids:\n",
    "        if ai_client.data_mart.subscriptions.get_details(sub)['entity']['asset']['name'] == MODEL_NAME:\n",
    "            subscription = ai_client.data_mart.subscriptions.get(sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get subscription list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<HTML>\n",
       "        <body>\n",
       "            <h3>Subscriptions</h3>\n",
       "            <table style='border: 1px solid #dddddd; font-family: Courier'>\n",
       "                <th style='border: 1px solid #dddddd'>uid</th><th style='border: 1px solid #dddddd'>name</th><th style='border: 1px solid #dddddd'>type</th><th style='border: 1px solid #dddddd'>binding_uid</th><th style='border: 1px solid #dddddd'>created</th>\n",
       "                <tr><td style='border: 1px solid #dddddd'>b197ce73-80df-48d2-8cb3-c5d7993119c7</td><td style='border: 1px solid #dddddd'>Scikit German Risk Model</td><td style='border: 1px solid #dddddd'>model</td><td style='border: 1px solid #dddddd'>fe0b229f-5167-4b9d-8b72-87bb3dcf4542</td><td style='border: 1px solid #dddddd'>2019-11-12T03:27:08.103Z</td></tr>\n",
       "            </table>\n",
       "        </body>\n",
       "        </HTML>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "subscriptions_uids = ai_client.data_mart.subscriptions.get_uids()\n",
    "ai_client.data_mart.subscriptions.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "subscription_details = subscription.get_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score the model so we can configure monitors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the WML service has been bound and the subscription has been created, we need to send a request to the model before we configure OpenScale. This allows OpenScale to create a payload log in the datamart with the correct schema, so it can capture data coming into and out of the model. First, the code gets the model deployment's endpoint URL, and then sends a few records for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24a0e195-2546-483f-86bc-1c15b25482cb\n",
      "https://us-south.ml.cloud.ibm.com/v3/wml_instances/fe0b229f-5167-4b9d-8b72-87bb3dcf4542/deployments/24a0e195-2546-483f-86bc-1c15b25482cb/online\n"
     ]
    }
   ],
   "source": [
    "credit_risk_scoring_endpoint = None\n",
    "print(deployment_uid)\n",
    "\n",
    "for deployment in wml_client.deployments.get_details()['resources']:\n",
    "    if deployment_uid in deployment['metadata']['guid']:\n",
    "        credit_risk_scoring_endpoint = deployment['entity']['scoring_url']\n",
    "        \n",
    "print(credit_risk_scoring_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single record scoring result: \n",
      " fields: ['prediction', 'probability'] \n",
      " values:  ['No Risk', [0.5355367798367918, 0.4644632201632082]]\n"
     ]
    }
   ],
   "source": [
    "fields = [\"CheckingStatus\",\"LoanDuration\",\"CreditHistory\",\"LoanPurpose\",\"LoanAmount\",\"ExistingSavings\",\"EmploymentDuration\",\"InstallmentPercent\",\"Sex\",\"OthersOnLoan\",\"CurrentResidenceDuration\",\"OwnsProperty\",\"Age\",\"InstallmentPlans\",\"Housing\",\"ExistingCreditsCount\",\"Job\",\"Dependents\",\"Telephone\",\"ForeignWorker\"]\n",
    "values = [\n",
    "  [\"no_checking\",13,\"credits_paid_to_date\",\"car_new\",1343,\"100_to_500\",\"1_to_4\",2,\"female\",\"none\",3,\"savings_insurance\",46,\"none\",\"own\",2,\"skilled\",1,\"none\",\"yes\"],\n",
    "  [\"no_checking\",24,\"prior_payments_delayed\",\"furniture\",4567,\"500_to_1000\",\"1_to_4\",4,\"male\",\"none\",4,\"savings_insurance\",36,\"none\",\"free\",2,\"management_self-employed\",1,\"none\",\"yes\"],\n",
    "  [\"0_to_200\",26,\"all_credits_paid_back\",\"car_new\",863,\"less_100\",\"less_1\",2,\"female\",\"co-applicant\",2,\"real_estate\",38,\"none\",\"own\",1,\"skilled\",1,\"none\",\"yes\"],\n",
    "  [\"0_to_200\",14,\"no_credits\",\"car_new\",2368,\"less_100\",\"1_to_4\",3,\"female\",\"none\",3,\"real_estate\",29,\"none\",\"own\",1,\"skilled\",1,\"none\",\"yes\"],\n",
    "  [\"0_to_200\",4,\"no_credits\",\"car_new\",250,\"less_100\",\"unemployed\",2,\"female\",\"none\",3,\"real_estate\",23,\"none\",\"rent\",1,\"management_self-employed\",1,\"none\",\"yes\"],\n",
    "  [\"no_checking\",17,\"credits_paid_to_date\",\"car_new\",832,\"100_to_500\",\"1_to_4\",2,\"male\",\"none\",2,\"real_estate\",42,\"none\",\"own\",1,\"skilled\",1,\"none\",\"yes\"],\n",
    "  [\"no_checking\",33,\"outstanding_credit\",\"appliances\",5696,\"unknown\",\"greater_7\",4,\"male\",\"co-applicant\",4,\"unknown\",54,\"none\",\"free\",2,\"skilled\",1,\"yes\",\"yes\"],\n",
    "  [\"0_to_200\",13,\"prior_payments_delayed\",\"retraining\",1375,\"100_to_500\",\"4_to_7\",3,\"male\",\"none\",3,\"real_estate\",37,\"none\",\"own\",2,\"management_self-employed\",1,\"none\",\"yes\"]\n",
    "]\n",
    "\n",
    "payload_scoring = {\"fields\": fields,\"values\": values}\n",
    "scoring_response = wml_client.deployments.score(credit_risk_scoring_endpoint, payload_scoring)\n",
    "\n",
    "print('Single record scoring result:', '\\n fields:', scoring_response['fields'], '\\n values: ', scoring_response['values'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fairness monitoring and explanations <a name=\"fairness\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below configures fairness monitoring for our model. It turns on monitoring for two features, Sex and Age. In each case, we must specify:\n",
    "  * Which model feature to monitor\n",
    "  * One or more **majority** groups, which are values of that feature that we expect to receive a higher percentage of favorable outcomes\n",
    "  * One or more **minority** groups, which are values of that feature that we expect to receive a higher percentage of unfavorable outcomes\n",
    "  * The threshold at which we would like OpenScale to display an alert if the fairness measurement falls below (in this case, 95%)\n",
    "\n",
    "Additionally, we must specify which outcomes from the model are favourable outcomes, and which are unfavourable. We must also provide the number of records OpenScale will use to calculate the fairness score. In this case, OpenScale's fairness monitor will run hourly, but will not calculate a new fairness rating until at least 200 records have been added. Finally, to calculate fairness, OpenScale must perform some calculations on the training data, so we provide the dataframe containing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "subscription.fairness_monitoring.enable(\n",
    "            features=[\n",
    "                Feature(\"Sex\", majority=['male'], minority=['female'], threshold=0.95),\n",
    "                Feature(\"Age\", majority=[[26,75]], minority=[[18,25]], threshold=0.95)\n",
    "            ],\n",
    "            favourable_classes=['No Risk'],\n",
    "            unfavourable_classes=['Risk'],\n",
    "            min_records=200,\n",
    "            training_data=train_data.copy()\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score the model again now that monitoring is configured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next section randomly selects 200 records from the data feed and sends those records to the model for predictions. This is enough to exceed the minimum threshold for records set in the previous section, which allows OpenScale to begin calculating fairness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-11-12 03:27:40--  https://raw.githubusercontent.com/pmservice/ai-openscale-tutorials/master/assets/historical_data/german_credit_risk/wml/german_credit_feed.json\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.48.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.48.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3076279 (2.9M) [text/plain]\n",
      "Saving to: ‘german_credit_feed.json’\n",
      "\n",
      "100%[======================================>] 3,076,279   --.-K/s   in 0.08s   \n",
      "\n",
      "2019-11-12 03:27:40 (37.8 MB/s) - ‘german_credit_feed.json’ saved [3076279/3076279]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!rm german_credit_feed.json\n",
    "!wget https://raw.githubusercontent.com/pmservice/ai-openscale-tutorials/master/assets/historical_data/german_credit_risk/wml/german_credit_feed.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score 200 randomly chosen records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "with open('german_credit_feed.json', 'r') as scoring_file:\n",
    "    scoring_data = json.load(scoring_file)\n",
    "\n",
    "fields = scoring_data['fields']\n",
    "values = []\n",
    "for _ in range(200):\n",
    "    values.append(random.choice(scoring_data['values']))\n",
    "payload_scoring = {\"fields\": fields, \"values\": values}\n",
    "\n",
    "scoring_response = wml_client.deployments.score(credit_risk_scoring_endpoint, payload_scoring)\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run fairness monitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kick off a fairness monitor run on current data. The monitor runs hourly, but can be manually initiated using the Python client, the REST API, or the graphical user interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_details = subscription.fairness_monitoring.run(background_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<HTML>\n",
       "        <body>\n",
       "            <h3>FairnessMetrics (binding_id=fe0b229f-5167-4b9d-8b72-87bb3dcf4542, subscription_id=b197ce73-80df-48d2-8cb3-c5d7993119c7)</h3>\n",
       "            <table style='border: 1px solid #dddddd; font-family: Courier'>\n",
       "                <th style='border: 1px solid #dddddd'>ts</th><th style='border: 1px solid #dddddd'>feature</th><th style='border: 1px solid #dddddd'>feature_value</th><th style='border: 1px solid #dddddd'>fairness_biased</th><th style='border: 1px solid #dddddd'>fairness_value</th><th style='border: 1px solid #dddddd'>fairness_fav_class</th><th style='border: 1px solid #dddddd'>binding_id</th><th style='border: 1px solid #dddddd'>subscription_id</th><th style='border: 1px solid #dddddd'>asset_revision</th><th style='border: 1px solid #dddddd'>deployment_id</th><th style='border: 1px solid #dddddd'>process</th>\n",
       "                <tr><td style='border: 1px solid #dddddd'>2019-11-12 03:36:34.142067+00:00</td><td style='border: 1px solid #dddddd'>Age</td><td style='border: 1px solid #dddddd'>[18, 25]</td><td style='border: 1px solid #dddddd'>False</td><td style='border: 1px solid #dddddd'>1.0</td><td style='border: 1px solid #dddddd'>75.0</td><td style='border: 1px solid #dddddd'>fe0b229f-5167-4b9d-8b72-87bb3dcf4542</td><td style='border: 1px solid #dddddd'>b197ce73-80df-48d2-8cb3-c5d7993119c7</td><td style='border: 1px solid #dddddd'>b197ce73-80df-48d2-8cb3-c5d7993119c7</td><td style='border: 1px solid #dddddd'>24a0e195-2546-483f-86bc-1c15b25482cb</td><td style='border: 1px solid #dddddd'></td></tr><tr><td style='border: 1px solid #dddddd'>2019-11-12 03:36:34.142067+00:00</td><td style='border: 1px solid #dddddd'>Sex</td><td style='border: 1px solid #dddddd'>female</td><td style='border: 1px solid #dddddd'>False</td><td style='border: 1px solid #dddddd'>0.872</td><td style='border: 1px solid #dddddd'>68.0</td><td style='border: 1px solid #dddddd'>fe0b229f-5167-4b9d-8b72-87bb3dcf4542</td><td style='border: 1px solid #dddddd'>b197ce73-80df-48d2-8cb3-c5d7993119c7</td><td style='border: 1px solid #dddddd'>b197ce73-80df-48d2-8cb3-c5d7993119c7</td><td style='border: 1px solid #dddddd'>24a0e195-2546-483f-86bc-1c15b25482cb</td><td style='border: 1px solid #dddddd'></td></tr>\n",
       "            </table>\n",
       "        </body>\n",
       "        </HTML>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "time.sleep(10)\n",
    "\n",
    "subscription.fairness_monitoring.show_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we provide OpenScale with the training data to enable and configure the explainability features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ibm_ai_openscale.supporting_classes import *\n",
    "\n",
    "subscription.explainability.enable(training_data=data_df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "explainability_details = subscription.explainability.get_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run explanation for sample record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9eda8a80b505625abaa15fd2ebabc2ec-1\n"
     ]
    }
   ],
   "source": [
    "transaction_id = subscription.payload_logging.get_table_content(limit=1)['scoring_id'].values[0]\n",
    "\n",
    "print(transaction_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "================================================================\n",
      "\n",
      " Looking for explanation for 9eda8a80b505625abaa15fd2ebabc2ec-1 \n",
      "\n",
      "================================================================\n",
      "\n",
      "\n",
      "\n",
      "in_progress.................\n",
      "finished\n",
      "\n",
      "---------------------------\n",
      " Successfully finished run \n",
      "---------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "explain_run = subscription.explainability.run(transaction_id=transaction_id, background_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>feature_value</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OwnsProperty</td>\n",
       "      <td>real_estate</td>\n",
       "      <td>0.223419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OthersOnLoan</td>\n",
       "      <td>none</td>\n",
       "      <td>0.176655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CheckingStatus</td>\n",
       "      <td>less_0</td>\n",
       "      <td>0.152519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sex</td>\n",
       "      <td>female</td>\n",
       "      <td>-0.092100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>InstallmentPlans</td>\n",
       "      <td>none</td>\n",
       "      <td>-0.083419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CreditHistory</td>\n",
       "      <td>all_credits_paid_back</td>\n",
       "      <td>0.080569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ForeignWorker</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.078008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Telephone</td>\n",
       "      <td>none</td>\n",
       "      <td>0.054011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EmploymentDuration</td>\n",
       "      <td>1_to_4</td>\n",
       "      <td>0.031097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Housing</td>\n",
       "      <td>rent</td>\n",
       "      <td>-0.028202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature_name          feature_value    weight\n",
       "0        OwnsProperty            real_estate  0.223419\n",
       "1        OthersOnLoan                   none  0.176655\n",
       "2      CheckingStatus                 less_0  0.152519\n",
       "3                 Sex                 female -0.092100\n",
       "4    InstallmentPlans                   none -0.083419\n",
       "5       CreditHistory  all_credits_paid_back  0.080569\n",
       "6       ForeignWorker                    yes  0.078008\n",
       "7           Telephone                   none  0.054011\n",
       "8  EmploymentDuration                 1_to_4  0.031097\n",
       "9             Housing                   rent -0.028202"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explain_result = pd.DataFrame.from_dict(explain_run['entity']['predictions'][0]['explanation_features'])\n",
    "explain_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations!\n",
    "\n",
    "You have finished the hands-on lab for IBM Watson OpenScale. You can now view the [OpenScale Dashboard](https://aiopenscale.cloud.ibm.com/). Click on the tile for the German Credit model to see fairness, accuracy, and performance monitors. Click on the timeseries graph to get detailed information on transactions during a specific time window.\n",
    "\n",
    "## Next steps\n",
    "\n",
    "OpenScale shows model performance over time. You have two options to keep data flowing to your OpenScale graphs:\n",
    "  * Download, configure and schedule the [model feed notebook](https://raw.githubusercontent.com/emartensibm/german-credit/master/german_credit_scoring_feed.ipynb). This notebook can be set up with your WML credentials, and scheduled to provide a consistent flow of scoring requests to your model, which will appear in your OpenScale monitors.\n",
    "  * Re-run this notebook. Running this notebook from the beginning will delete and re-create the model and deployment. Please note that the payload and measurement logs for the previous deployment will continue to be stored in your datamart, and can be deleted if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "\n",
    "Eric Martens, is a technical specialist having expertise in analysis and description of business processes, and their translation into functional and non-functional IT requirements. He acts as the interpreter between the worlds of IT and business.\n",
    "\n",
    "Lukasz Cmielowski, PhD, is an Automation Architect and Data Scientist at IBM with a track record of developing enterprise-level applications that substantially increases clients' ability to turn data into actionable knowledge."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
